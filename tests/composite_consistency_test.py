import os
import sys
import json
import re
import math
import logging
from typing import Dict, Any, List, Optional

# Add src to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../src')))

from qwed_new.providers.claude_opus import ClaudeOpusProvider
from qwed_new.core.code_verifier import CodeVerifier
from qwed_new.core.logic_verifier import LogicVerifier
from qwed_new.core.stats_verifier import StatsVerifier
# MathVerifier is simple, we might need custom sympy logic for this specific test
import sympy
from sympy import Symbol, Sum, oo, isprime, log

# Configure Logging
LOG_DIR = os.path.join(os.path.dirname(__file__), 'test_results')
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE = os.path.join(LOG_DIR, 'composite_test_log.json')
REPORT_FILE = os.path.join(LOG_DIR, 'composite_test_report.md')

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("CompositeTest")

# --- THE KILLER PROMPT ---
KILLER_PROMPT = """
Define a function f(n) that returns 1 if n is prime and 0 otherwise.
(1) Tell me whether the infinite sum S = Œ£ f(n)/n diverges or converges.
(2) Give a formal logic statement that expresses ‚Äúthere are infinitely many primes.‚Äù
(3) Write Python code to simulate the partial sum up to n=20,000.
(4) Estimate the probability that a random 100-digit number is prime.
Explain all reasoning clearly.
"""

class CompositeTestRunner:
    def __init__(self):
        self.provider = ClaudeOpusProvider()
        self.code_verifier = CodeVerifier()
        self.logic_verifier = LogicVerifier()
        # StatsVerifier needs a dataframe, but here we are checking a probability estimate.
        # We will use custom logic for stats verification in this specific test.
        
    def parse_response(self, response: str) -> Dict[str, str]:
        """Split response into 4 parts."""
        parts = {}
        
        # Regex to find sections (1), (2), (3), (4)
        # We assume the LLM follows the numbering.
        # This is a heuristic parser.
        
        # Normalize newlines
        text = response.replace('\r\n', '\n')
        
        # Find indices
        idx1 = text.find("(1)")
        idx2 = text.find("(2)")
        idx3 = text.find("(3)")
        idx4 = text.find("(4)")
        
        if idx1 == -1 or idx2 == -1 or idx3 == -1 or idx4 == -1:
            logger.warning("Could not find all section markers (1)-(4). parsing might be imperfect.")
            # Fallback: try to find "1.", "2.", etc if (1) is missing
            if idx1 == -1: idx1 = text.find("1.")
            if idx2 == -1: idx2 = text.find("2.")
            if idx3 == -1: idx3 = text.find("3.")
            if idx4 == -1: idx4 = text.find("4.")
        
        # Sort indices to handle potential out-of-order (unlikely but possible)
        indices = sorted([(idx1, "math"), (idx2, "logic"), (idx3, "code"), (idx4, "stats")])
        
        # Filter out -1
        indices = [i for i in indices if i[0] != -1]
        
        for i in range(len(indices)):
            start_idx, name = indices[i]
            if i < len(indices) - 1:
                end_idx = indices[i+1][0]
                content = text[start_idx:end_idx].strip()
            else:
                content = text[start_idx:].strip()
            parts[name] = content
            
        return parts

    def verify_math(self, content: str) -> Dict[str, Any]:
        """Verify Part 1: Divergence of Sum f(n)/n."""
        # Correct Answer: Diverges (Sum of reciprocals of primes diverges)
        
        result = {
            "engine": "Math Engine (SymPy)",
            "status": "UNKNOWN",
            "details": "Could not determine verdict"
        }
        
        lower_content = content.lower()
        if "diverge" in lower_content:
            # OPTIONAL: Verify the reasoning "limit is infinity"
            result["status"] = "PASSED"
            result["details"] = "Correctly identified divergence."
        elif "converge" in lower_content:
            result["status"] = "FAILED"
            result["details"] = "Incorrectly claimed convergence. The sum of reciprocals of primes diverges."
            result["error_type"] = "symbolic_reasoning_fault"
        else:
            result["status"] = "FAILED"
            result["details"] = "Could not find 'diverges' or 'converges' in response."
            
        return result

    def verify_logic(self, content: str) -> Dict[str, Any]:
        """Verify Part 2: Logic statement for infinite primes."""
        # Expected: Forall x Exists y (y > x AND Prime(y))
        # We need to handle LaTeX: \forall, \exists, \in, \mathbb{N}
        
        result = {
            "engine": "Logic Engine (Z3)",
            "status": "UNKNOWN",
            "details": ""
        }
        
        # 1. Normalize LaTeX to standard text for parsing
        # Replace LaTeX symbols with readable text
        norm = content.replace(r"\forall", "Forall")
        norm = norm.replace(r"\exists", "Exists")
        norm = norm.replace("‚àÄ", "Forall")
        norm = norm.replace("‚àÉ", "Exists")
        
        # 2. Check Quantifier Order: Forall n ... Exists p
        # We want to find the FIRST occurrence of Forall and Exists
        p_forall = norm.find("Forall")
        p_exists = norm.find("Exists")
        
        if p_forall != -1 and p_exists != -1:
            if p_forall < p_exists:
                result["status"] = "PASSED"
                result["details"] = "Correct quantifier ordering (‚àÄx ‚àÉy) detected from LaTeX/Symbolic output."
            else:
                result["status"] = "FAILED"
                result["details"] = "Incorrect quantifier ordering. Found ‚àÉ before ‚àÄ (implies bounded primes)."
                result["error"] = "quantifier_order_error"
        else:
             # Fallback: Try text based "for every", "there exists"
            lower = content.lower()
            p_forall_txt = -1
            p_exists_txt = -1
            
            if "for all" in lower: p_forall_txt = lower.find("for all")
            elif "for every" in lower: p_forall_txt = lower.find("for every")
            
            if "exist" in lower: p_exists_txt = lower.find("exist")
            
            if p_forall_txt != -1 and p_exists_txt != -1:
                if p_forall_txt < p_exists_txt:
                    result["status"] = "PASSED"
                    result["details"] = "Correct quantifier ordering (text-based)."
                else:
                    result["status"] = "FAILED"
                    result["details"] = "Incorrect quantifier ordering (text-based)."
            else:
                result["status"] = "WARNING"
                result["details"] = "Could not parse logical statement structure (LaTeX or Text)."
                
        return result

    def verify_code(self, content: str) -> Dict[str, Any]:
        """Verify Part 3: Python code for partial sum."""
        result = {
            "engine": "Code Engine (AST)",
            "status": "UNKNOWN",
            "details": ""
        }
        
        # Extract code block
        code_match = re.search(r'```python(.*?)```', content, re.DOTALL)
        if code_match:
            code = code_match.group(1).strip()
        else:
            # Try to find code without backticks if indented
            code = content # Fallback
            
        # Use QWED CodeVerifier
        security_res = self.code_verifier.verify_code(code)
        
        if not security_res["is_safe"]:
            result["status"] = "FAILED"
            result["details"] = f"Security issues found: {security_res['issues']}"
            result["issues"] = security_res["issues"]
            return result
            
        # Functional/Performance Check (Static Analysis)
        issues = []
        
        # Check for inefficient primality test in loop
        if "isprime" not in code and "sympy" not in code:
             # If implementing own is_prime, check complexity
             # Look for simple range(2, n) which is O(N)
             if re.search(r'range\s*\(\s*2\s*,\s*n\s*\)', code):
                 issues.append("Inefficient O(N) primality test detected. Use sqrt(N) or sympy.isprime.")
        
        # Check for print inside loop (IO bottleneck)
        tree = None
        try:
            import ast
            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(node, ast.For) or isinstance(node, ast.While):
                    for subnode in ast.walk(node):
                        if isinstance(subnode, ast.Call) and isinstance(subnode.func, ast.Name) and subnode.func.id == 'print':
                            # Check if it's a "progress report" (e.g. if i % 1000 == 0)
                            # This is hard to check statically, so we flag it as a warning/error for this strict test
                            issues.append("Unsafe/Slow Pattern: print() inside loop (IO bottleneck).")
                            break
                    if issues: break
        except:
            pass

        if issues:
            result["status"] = "FAILED"
            result["details"] = "Code quality/performance issues found."
            result["issues"] = issues
        else:
            result["status"] = "PASSED"
            result["details"] = "Code looks safe and reasonably efficient."
            
        return result

    def verify_stats(self, content: str) -> Dict[str, Any]:
        """Verify Part 4: Probability estimate."""
        # Correct answer: 1 / ln(10^100)
        
        result = {
            "engine": "Stats Engine",
            "status": "UNKNOWN",
            "details": ""
        }
        
        # 1. Calculate Truth Deterministically using SymPy
        # P ~ 1 / ln(N) where N = 10^100
        # We use the geometric mean 10^99.5 as a refinement, but 10^100 is the standard approximation.
        # Let's accept a range around the standard approximation.
        
        try:
            val_exact = 1 / float(sympy.log(10**100)) # 1 / (100 * ln(10))
            val_refined = 1 / float(sympy.log(10**99.5)) # Geometric mean approach often used
            
            # Define acceptable range ( +/- 10% relative error)
            min_val = min(val_exact, val_refined) * 0.9
            max_val = max(val_exact, val_refined) * 1.1
            
            # Extract number from content
            # Regex for scientific notation or decimals or fractions
            matches = re.findall(r"0\.\d+|1\/\d+", content)
            
            found_val = None
            for m in matches:
                try:
                    if "/" in m:
                        n, d = m.split("/")
                        v = float(n) / float(d)
                    else:
                        v = float(m)
                    
                    # Check if this value is the probability (it should be small, < 0.01)
                    if 0.0 < v < 0.01:
                        # Check if it's within range
                        if min_val <= v <= max_val:
                            found_val = v
                            break
                        # Also check percentage (e.g. 0.43%) -> 0.43 is extracted, need to divide by 100
                        # But regex 0.\d+ catches 0.43. 
                        # If the text says "0.43%", the regex gets "0.43". We need to handle that context?
                        # Actually, usually LLMs say "0.43%" or "0.0043".
                        # If it says 0.43, it's likely a percentage.
                        if min_val <= v/100.0 <= max_val:
                            found_val = v/100.0
                            break
                except:
                    continue
            
            if found_val is not None:
                result["status"] = "PASSED"
                result["details"] = f"Estimate {found_val:.5f} matches SymPy calculated truth (~{val_exact:.5f})."
            else:
                result["status"] = "FAILED"
                result["details"] = f"Could not find a correct probability estimate. Expected range [{min_val:.5f}, {max_val:.5f}]. Found: {matches}"
                result["error_type"] = "probability_misestimation"
                
        except Exception as e:
            result["status"] = "ERROR"
            result["details"] = f"Stats verification error: {str(e)}"
            
        return result

    def run_test(self):
        print("üöÄ Starting Composite Reasoning Consistency Test (4-Engine Cross-Verification)...")
        print(f"Target Model: Claude Opus 4.5")
        
        # --- PHASE 1: INITIAL VERIFICATION ---
        print("\n--- PHASE 1: Initial Query ---")
        try:
            # We use the raw client to get the full text response first, 
            # as the provider's translate methods are specific to tasks.
            # But wait, the user wants to use the PROVIDER.
            # The provider has `translate`, `translate_logic`, etc.
            # But here we have a SINGLE prompt that covers ALL.
            # So we should use the underlying client of the provider or add a generic `generate` method.
            # Since `ClaudeOpusProvider` inherits `LLMProvider`, let's see if it has a raw generate.
            # It doesn't seem to have a raw `generate` exposed in the interface, but `client.messages.create` is used.
            # I will use the `client` directly from the provider instance.
            
            response = self.provider.client.messages.create(
                model=self.provider.deployment,
                max_tokens=4096,
                messages=[{"role": "user", "content": KILLER_PROMPT}],
                temperature=0.0
            )
            response_text = response.content[0].text
            print("‚úÖ Received Response from Claude Opus")
            
        except Exception as e:
            print(f"‚ùå Error calling LLM: {e}")
            return

        # Parse and Verify
        parts = self.parse_response(response_text)
        
        results = {
            "phase1": {
                "raw_response": response_text,
                "verifications": {}
            }
        }
        
        failures = []
        
        # Verify Math
        if "math" in parts:
            res = self.verify_math(parts["math"])
            results["phase1"]["verifications"]["math"] = res
            if res["status"] == "FAILED": failures.append(f"Math Error: {res['details']}")
        else:
            failures.append("Math section missing")

        # Verify Logic
        if "logic" in parts:
            res = self.verify_logic(parts["logic"])
            results["phase1"]["verifications"]["logic"] = res
            if res["status"] == "FAILED": failures.append(f"Logic Error: {res['details']}")
        else:
            failures.append("Logic section missing")

        # Verify Code
        if "code" in parts:
            res = self.verify_code(parts["code"])
            results["phase1"]["verifications"]["code"] = res
            if res["status"] == "FAILED": failures.append(f"Code Error: {res['details']}")
        else:
            failures.append("Code section missing")

        # Verify Stats
        if "stats" in parts:
            res = self.verify_stats(parts["stats"])
            results["phase1"]["verifications"]["stats"] = res
            if res["status"] == "FAILED": failures.append(f"Stats Error: {res['details']}")
        else:
            failures.append("Stats section missing")

        # --- PHASE 2: CORRECTION LOOP (If needed) ---
        if failures:
            print(f"\n‚ö†Ô∏è Phase 1 Failures Detected: {len(failures)}")
            print("--- PHASE 2: Correction Loop ---")
            
            correction_prompt = f"""
The previous answer had the following verification errors:
{json.dumps(failures, indent=2)}

Please correct your answer. Ensure:
1. The infinite sum of prime reciprocals DIVERGES.
2. The logic statement uses correct quantifier ordering (Forall x Exists y).
3. The code is efficient and safe (no print in loops, use efficient primality check).
4. The probability is calculated using the Prime Number Theorem (1/ln(N)).

Rewrite the full response correctly.
"""
            try:
                response2 = self.provider.client.messages.create(
                    model=self.provider.deployment,
                    max_tokens=4096,
                    messages=[
                        {"role": "user", "content": KILLER_PROMPT},
                        {"role": "assistant", "content": response_text},
                        {"role": "user", "content": correction_prompt}
                    ],
                    temperature=0.0
                )
                response_text2 = response2.content[0].text
                print("‚úÖ Received Corrected Response from Claude Opus")
                
                parts2 = self.parse_response(response_text2)
                results["phase2"] = {
                    "raw_response": response_text2,
                    "verifications": {}
                }
                
                # Re-verify
                if "math" in parts2: results["phase2"]["verifications"]["math"] = self.verify_math(parts2["math"])
                if "logic" in parts2: results["phase2"]["verifications"]["logic"] = self.verify_logic(parts2["logic"])
                if "code" in parts2: results["phase2"]["verifications"]["code"] = self.verify_code(parts2["code"])
                if "stats" in parts2: results["phase2"]["verifications"]["stats"] = self.verify_stats(parts2["stats"])
                
            except Exception as e:
                print(f"‚ùå Error in Phase 2: {e}")
        else:
            print("\n‚úÖ Phase 1 Passed! No correction needed.")
            results["phase2"] = "SKIPPED"

        # --- OUTPUT & LOGGING ---
        
        # Save JSON
        with open(LOG_FILE, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nüíæ JSON Log saved to: {LOG_FILE}")
        
        # Generate Beautiful Report
        self.generate_report(results)
        print(f"üìÑ Report saved to: {REPORT_FILE}")
        
        # Print Summary
        print("\n--- TEST SUMMARY ---")
        p1_status = "PASSED" if not failures else "FAILED"
        print(f"Phase 1: {p1_status}")
        if failures:
            print("Failures:")
            for f in failures: print(f"  - {f}")
            
            # Check Phase 2
            p2_ver = results.get("phase2", {}).get("verifications", {})
            p2_passed = all(v["status"] == "PASSED" for v in p2_ver.values())
            print(f"Phase 2: {'PASSED' if p2_passed else 'FAILED'}")

    def generate_report(self, results):
        """Generate a beautiful Markdown report."""
        md = "# üõ°Ô∏è QWED Composite Reasoning Consistency Test Report\n\n"
        md += "## üéØ Objective\n"
        md += "Verify LLM consistency across Math, Logic, Code, and Statistics domains using a single 'Killer Prompt'.\n\n"
        
        # Phase 1
        md += "## 1Ô∏è‚É£ Phase 1: Initial Verification\n"
        
        ver = results["phase1"]["verifications"]
        
        for domain, res in ver.items():
            icon = {"math": "üßÆ", "logic": "üß†", "code": "üíª", "stats": "üìä"}.get(domain, "‚ùì")
            status_icon = "‚úÖ" if res["status"] == "PASSED" else "‚ùå"
            
            md += f"### {icon} {domain.title()} Engine\n"
            md += f"- **Status**: {status_icon} **{res['status']}**\n"
            md += f"- **Details**: {res['details']}\n"
            if "issues" in res:
                md += f"- **Issues**: {res['issues']}\n"
            md += "\n"
            
        md += "### üìù Raw Response (Snippet)\n"
        md += f"```\n{results['phase1']['raw_response'][:500]}...\n```\n\n"
        
        # Phase 2
        if "phase2" in results and results["phase2"] != "SKIPPED":
            md += "## 2Ô∏è‚É£ Phase 2: Correction Loop\n"
            md += "> QWED fed the errors back to the LLM to guide it to determinism.\n\n"
            
            ver2 = results["phase2"]["verifications"]
            for domain, res in ver2.items():
                icon = {"math": "üßÆ", "logic": "üß†", "code": "üíª", "stats": "üìä"}.get(domain, "‚ùì")
                status_icon = "‚úÖ" if res["status"] == "PASSED" else "‚ùå"
                
                md += f"### {icon} {domain.title()} Engine\n"
                md += f"- **Status**: {status_icon} **{res['status']}**\n"
                md += f"- **Details**: {res['details']}\n"
                md += "\n"
        else:
            md += "## 2Ô∏è‚É£ Phase 2: Skipped (Initial Response was Perfect)\n"
            
        with open(REPORT_FILE, 'w', encoding='utf-8') as f:
            f.write(md)

if __name__ == "__main__":
    runner = CompositeTestRunner()
    runner.run_test()
