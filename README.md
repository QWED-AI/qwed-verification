# QWED Protocol Verification

> **Deterministically verify LLM outputs in CI using Z3 + SymPy so hallucinations never reach production.**

[![GitHub Marketplace](https://img.shields.io/badge/Marketplace-QWED%20Protocol-blue?style=for-the-badge&logo=github)](https://github.com/marketplace/actions/qwed-protocol-verification)
[![Verified by QWED](https://img.shields.io/badge/Verified_by-QWED-00C853?style=flat&logo=checkmarx)](https://github.com/QWED-AI/qwed-verification)
[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](LICENSE)

## ðŸš€ Why use this Action?
*   **Block Hallucinations:** Prevents AI errors from merging into main.
*   **Model Agnostic:** Works with OpenAI, Claude, Llama, or any local model.
*   **Zero-Trust:** Uses symbolic verification (Math, Logic, Code), not just "another LLM checking the first one."
*   **Drop-in:** Add to your workflow in 2 minutes. No infrastructure required.

```yaml
# âš¡ Quick Example
- uses: QWED-AI/qwed-verification@v2.4.1
  with:
    query: "Calculate derivative of x^2"
    llm_output: "3x" # Wrong!
    engine: "math"
# Fails CI with: "âŒ CORRECTED: 2x"
```

---

## ðŸ”Œ How to use in your pipeline

### 1. Verify PRs (Pull Request Gate)
Use this to ensure every code or documentation change generated by an AI Agent works as intended.

```yaml
name: Verify AI Changes
on: [pull_request]

jobs:
  verify:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Verify Math Logic
        uses: QWED-AI/qwed-verification@v2.4.1
        with:
          query: "Calculate total cost: 5 units at $10.50"
          llm_output: "${{ steps.ai_agent.outputs.answer }}" 
          engine: "math"
```

### 2. Production Gate (Deployment)
Run a suite of verifications before deploying to production.

```yaml
name: Production Safeguard
on: 
  release:
    types: [published]

jobs:
  safety-check:
    runs-on: ubuntu-latest
    steps:
      - name: Verify Logic Consistency
        uses: QWED-AI/qwed-verification@v2.4.1
        with:
          query: "If Start=Monday and End=Wednesday, is duration 5 days?"
          llm_output: "Yes"
          engine: "logic"
        # Fails job if logic is invalid
```

---

## ðŸŽ›ï¸ Inputs & Outputs

| Type | Name | Description | Default |
|------|------|-------------|---------|
| **Input** | `query` | The user prompt or question (e.g. "Derivative of x^2") | Required |
| **Input** | `llm_output` | The AI's response to verify | Required |
| **Input** | `engine` | Verification engine: `math`, `logic`, `sql`, `code`, `facts` | `math` |
| **Input** | `api_key` | QWED API Key (optional for local/docker mode) | `""` |
| **Output** | `verified` | `true` if mathematically correct, `false` otherwise | - |
| **Output** | `explanation` | Detailed proof or error message | - |
| **Failure**| `exit code` | Non-zero if verification fails (blocks pipeline) | - |

---

## ðŸ›¡ï¸ Use Case Examples

*   **Legal:** Block a contract summary if the deadline calculation differs from calendar logic.
*   **Finance:** Fail CI if the NPV/IRR for a deal computed by an LLM deviates from the reference formula.
*   **Commerce:** Reject refund/discount decisions that violate your strict business rules (UCP).
*   **Code:** Prevent `rm -rf` or SQL injection patterns from being committed by coding agents.

---

## ðŸ“¦ Installation (Python Library)
If you aren't using GitHub Actions, you can use the Python library directly:

```bash
pip install qwed
```

---

## ðŸ”— Learn More
*   **Full Documentation:** [docs.qwedai.com](https://docs.qwedai.com)
*   **Core Concepts:** [Theory & Philosophy](docs/CORE_CONCEPTS.md)
*   **Free Course:** [qwed-learning](https://github.com/QWED-AI/qwed-learning)
*   **Ecosystem:**
    *   [qwed-finance](https://github.com/QWED-AI/qwed-finance)
    *   [qwed-legal](https://github.com/QWED-AI/qwed-legal)
    *   [qwed-infra](https://github.com/QWED-AI/qwed-infra)

> **Who is this for?**
> *   Platform Engineering teams building AI Agents.
> *   Security/Compliance teams mandating deterministic safety.
> *   Developers who want to sleep at night knowing their AI won't segfault production.

*Backed by formal research. [Read the Whitepaper](docs/WHITEPAPER.md).*
